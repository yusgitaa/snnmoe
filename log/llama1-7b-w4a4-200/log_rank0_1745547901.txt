[2025-04-25 10:25:01 root] (main.py 276): INFO Namespace(a_dynamic_method='per_token', abits=4, act_scales=None, act_shifts=None, addbit=1, alpha=0.75, attn_implementation='eager', aug_loss=False, batch_size=1, cache_dir='./cache', calib_dataset='wikitext2', deactive_amp=False, disable_zero_point=False, epochs=1, eval_ppl=True, group_size=None, let=False, let_lr=0.001, limit=-1, low_p=0.9, lwc=True, lwc_lr=0.01, model='Mixtral-8x7B-Instruct-v0.1/', multigpu=False, net='mixtral-8x7b', nsamples=1, num_fewshot=0, output_dir='./log/llama1-7b-w4a4-200', real_quant=True, resume=None, save_dir=None, seed=2, symmetric=False, tasks='piqa', w_dynamic_method='per_channel', wbits=4, wd=0)
[2025-04-25 10:28:28 root] (main.py 372): INFO === start quantization ===
[2025-04-25 10:28:28 root] (main.py 378): INFO load calibration from ./cache/dataloader_mixtral_wikitext2_1.cache
[2025-04-25 10:28:28 root] (spike_omniquant.py 115): INFO Starting ...
[2025-04-25 10:28:28 root] (spike_omniquant.py 118): INFO Moving the entire model to GPU for initial processing...
