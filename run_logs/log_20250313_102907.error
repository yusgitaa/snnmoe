usage: train.py [-h] [-data-dir DIR] [--dataset NAME] [--train-split NAME]
                [--val-split NAME] [--train-split-path N] [--model MODEL]
                [--pooling-stat POOLING_STAT] [--TET TET]
                [--TET-means TET_MEANS] [--TET-lamb TET_LAMB]
                [--spike-mode SPIKE_MODE] [--layer LAYER]
                [--in-channels IN_CHANNELS] [--pretrained]
                [--initial-checkpoint PATH] [--resume PATH] [--no-resume-opt]
                [--num-classes N] [--time-steps N] [--num-heads N]
                [--patch-size N] [--mlp-ratio N] [--gp POOL] [--img-size N]
                [--input-size N N N N N N N N N] [--crop-pct N]
                [--mean MEAN [MEAN ...]] [--std STD [STD ...]]
                [--interpolation NAME] [-b N] [-vb N] [--opt OPTIMIZER]
                [--opt-eps EPSILON] [--opt-betas BETA [BETA ...]]
                [--momentum M] [--weight-decay WEIGHT_DECAY]
                [--clip-grad NORM] [--clip-mode CLIP_MODE] [--sched SCHEDULER]
                [--lr LR] [--lr-noise pct, pct [pct, pct ...]]
                [--lr-noise-pct PERCENT] [--lr-noise-std STDDEV]
                [--lr-cycle-mul MULT] [--lr-cycle-limit N] [--warmup-lr LR]
                [--min-lr LR] [--epochs N] [--epoch-repeats N]
                [--start-epoch N] [--decay-epochs N] [--warmup-epochs N]
                [--cooldown-epochs N] [--patience-epochs N]
                [--decay-rate RATE] [--no-aug] [--scale PCT [PCT ...]]
                [--ratio RATIO [RATIO ...]] [--hflip HFLIP] [--vflip VFLIP]
                [--color-jitter PCT] [--aa NAME] [--aug-splits AUG_SPLITS]
                [--jsd] [--bce-loss] [--bce-target-thresh BCE_TARGET_THRESH]
                [--reprob PCT] [--remode REMODE] [--recount RECOUNT]
                [--resplit] [--mixup MIXUP] [--cutmix CUTMIX]
                [--cutmix-minmax CUTMIX_MINMAX [CUTMIX_MINMAX ...]]
                [--mixup-prob MIXUP_PROB]
                [--mixup-switch-prob MIXUP_SWITCH_PROB]
                [--mixup-mode MIXUP_MODE] [--mixup-off-epoch N]
                [--smoothing SMOOTHING]
                [--train-interpolation TRAIN_INTERPOLATION] [--drop PCT]
                [--drop-connect PCT] [--drop-path PCT] [--drop-block PCT]
                [--bn-tf] [--bn-momentum BN_MOMENTUM] [--bn-eps BN_EPS]
                [--sync-bn] [--dist-bn DIST_BN] [--split-bn] [--linear-prob]
                [--model-ema] [--model-ema-force-cpu]
                [--model-ema-decay MODEL_EMA_DECAY] [--seed S]
                [--log-interval N] [--recovery-interval N]
                [--checkpoint-hist N] [-j N] [--save-images] [--amp]
                [--apex-amp] [--native-amp] [--channels-last] [--pin-mem]
                [--no-prefetcher] [--dvs-aug] [--dvs-trival-aug]
                [--output PATH] [--experiment NAME]
                [--eval-metric EVAL_METRIC] [--tta N]
                [--local_rank LOCAL_RANK] [--use-multi-epochs-loader]
                [--torchscript] [--log-wandb]
train.py: error: unrecognized arguments: --use-moe-mlp --n-routed-experts 4 --n-shared-experts 1 --num-experts-per-tok 1 --use-wandb --wandb-project snnmoe --wandb-name moe_mlp --wandb-offline
